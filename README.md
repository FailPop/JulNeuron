# Распознавание CAPTCHA с использованием CRNN (PyTorch)

## Описание

Данный проект представляет собой Python-скрипт для обучения модели глубокого обучения (CRNN - Convolutional Recurrent Neural Network) с целью распознавания текста на изображениях CAPTCHA. Скрипт включает в себя полный цикл MLOps: загрузку и предобработку данных из различных источников, обучение модели, логирование процесса, сохранение чекпоинтов, а также оценку производительности.

## Возможности

*   **Гибкая загрузка данных**: Поддержка множества форматов датасетов CAPTCHA благодаря кастомным парсерам для известных наборов данных.
*   **Предобработка изображений**: Включает изменение размера, преобразование в оттенки серого и нормализацию.
*   **Архитектура CRNN**: Модель состоит из сверточных слоев (CNN) для извлечения признаков и рекуррентных слоев (LSTM) для обработки последовательностей.
*   **Обучение с CTC Loss**: Используется функция потерь Connectionist Temporal Classification (CTC), подходящая для задач распознавания последовательностей без точного выравнивания.
*   **Управление обучением**:
    *   Сохранение и загрузка чекпоинтов (включая автозагрузку последнего или аварийного).
    *   Адаптивное изменение скорости обучения (`ReduceLROnPlateau`).
    *   Подробное логирование метрик обучения и валидации (в файл и консоль).
    *   Построение и сохранение графиков истории обучения (потери, точность).
    *   Обработка прерываний (Ctrl+C) для корректного завершения и сохранения.
    *   Обнаружение и обработка невалидных данных в датасете.
*   **Конфигурируемость**: Ключевые параметры обучения (размеры изображений, batch size, эпохи, пути к данным, параметры оптимизатора и т.д.) задаются через глобальный словарь `CONFIG`.
*   **Поддержка кириллицы и латиницы**: Алфавит для распознавания включает русские, английские буквы (в обоих регистрах) и цифры.
*   **Воспроизводимость**: Установка `seed` для PyTorch, NumPy для более детерминированных результатов.

## Начало Работы

### Предварительные требования

*   Python 3.7+
*   PyTorch (например, 1.7+ или новее)
*   Torchvision (соответствующей версии PyTorch)
*   NumPy
*   Pillow (PIL)
*   tqdm
*   Matplotlib
*   Pandas
*   pip (для установки зависимостей)

### Установка

1.  Клонируйте репозиторий:
    ```bash
    git clone [URL репозитория]
    ```
2.  Перейдите в директорию проекта:
    ```bash
    cd [название-директории-проекта]
    ```
3.  Создайте и активируйте виртуальное окружение (рекомендуется):
    ```bash
    python -m venv venv
    source venv/bin/activate  # для Linux/macOS
    # venv\Scripts\activate    # для Windows
    ```
4.  Создайте файл `requirements.txt` со следующим содержимым:
    ```txt
    torch
    torchvision
    numpy
    Pillow
    tqdm
    matplotlib
    pandas
    ```
    Затем выполните команду для установки зависимостей:
    ```bash
    pip install -r requirements.txt
    ```

### Подготовка Набора Данных

1.  **Структура директорий**:
    Скрипт ожидает, что наборы данных CAPTCHA будут находиться в базовой директории, указанной в `CONFIG["DATASET_BASE_DIR"]` (по умолчанию `"captcha_datasets"`). Каждый отдельный датасет должен быть в своей поддиректории внутри `DATASET_BASE_DIR`.
    Пример:
    ```
    captcha_datasets/
    ├── dataset1_name/  # Например, '5000-labelled-captcha-for-deeplearning'
    │   ├── image0001.png
    │   ├── image0002.jpg
    │   └── ... (файлы изображений или CSV с метками)
    ├── dataset2_name/  # Например, 'captcha-version-2-images'
    │   └── samples/
    │       └── imageA.png
    └── ...
    ```

2.  **Поддерживаемые форматы и парсеры**:
    Скрипт включает в себя парсеры для автоматического определения меток из различных известных датасетов CAPTCHA, таких как:
    *   `captcha-dataset` (от ParsaSam, с `captcha_data.csv` или метками в именах файлов)
    *   `5000-labelled-captcha-for-deeplearning` (от tomtillo, с `labels_level_X.csv`)
    *   `large-captcha-dataset` (от akashguna, метки в именах файлов в поддиректории `Large_Captcha_Dataset`)
    *   `captcha-version-2-images` (от fournierp, метки в именах файлов в поддиректории `samples`)
    *   `5char-captcha-dataset` (от amirhoseinvedadi, метки в именах файлов в поддиректории `captcha_dataset`)
    *   `capcha-images-to-training-data` (от mrigaankjaswal, метки в именах файлов в поддиректории `samples`)
    *   `captcha6digits` (от ethan404, метки в именах файлов)
    *   Датасеты от `huthayfahodeb` (с CSV файлами `labels.csv` или `solutions.csv`, или метками в именах файлов в поддиректории `samples`)

    Скрипт пытается идентифицировать датасет по имени его папки и применить соответствующий парсер. Если метки закодированы в именах файлов, скрипт также попытается их извлечь.

3.  **Исключение датасетов**:
    Некоторые датасеты могут быть исключены из обработки путем добавления их имен (названий папок) в список `CONFIG["EXCLUDED_DATASETS"]`.

4.  **Алфавит**:
    Скрипт использует фиксированный алфавит, определенный как `DEFAULT_ALPHABET` в коде. Он включает цифры, латинские (верхний и нижний регистр) и русские (верхний и нижний регистр) буквы. Метки, содержащие символы не из этого алфавита, будут отфильтрованы (удаляются недопустимые символы). Если после фильтрации метка становится пустой, она пропускается.

## Использование

### Конфигурация

Основные параметры скрипта настраиваются в словаре `CONFIG` в начале файла `имя_вашего_скрипта.py`. Ключевые параметры:

*   `DATASET_BASE_DIR`: Путь к корневой папке с датасетами.
*   `EXCLUDED_DATASETS`: Список папок с датасетами для исключения.
*   `CHECKPOINT_DIR`: Директория для сохранения чекпоинтов модели.
*   `RESULTS_DIR`: Директория для сохранения результатов (например, графика истории обучения `history.png` и лог-файла).
*   `IMAGE_HEIGHT`, `IMAGE_WIDTH`: Размеры изображений после предобработки.
*   `BATCH_SIZE`: Размер батча для обучения и валидации.
*   `EPOCHS`: Количество эпох обучения.
*   `LEARNING_RATE`: Начальная скорость обучения.
*   `OPTIMIZER_BETA1`, `OPTIMIZER_BETA2`: Параметры для оптимизатора AdamW.
*   `CLIP_GRAD_NORM`: Максимальное значение нормы градиента (для предотвращения "взрыва" градиентов).
*   `NUM_WORKERS`: Количество потоков для загрузки данных.
*   `TRAIN_VAL_SPLIT_RATIO`: Доля данных для обучающей выборки (остальное пойдет в валидационную).
*   `SEED`: Зерно для инициализации генераторов случайных чисел для воспроизводимости.

### Запуск Обучения

Для запуска процесса обучения выполните Python-скрипт:

```bash
python имя_вашего_скрипта.py
```

(Замените `имя_вашего_скрипта.py` на актуальное имя файла, содержащего предоставленный код).

Процесс обучения будет выводить логи в консоль и в файл `captcha_training_focused.log` (создается в той же директории, где запускается скрипт). Графики потерь и точности будут сохранены как `history.png` в директории, указанной в `CONFIG["RESULTS_DIR"]`. Чекпоинты модели (например, `captcha_model_last.pth`, `captcha_model_best_loss.pth`) будут сохраняться в `CONFIG["CHECKPOINT_DIR"]`.

Скрипт автоматически попытается загрузить последний чекпоинт из `CHECKPOINT_DIR`, если он существует и совместим (по алфавиту).

## Архитектура Модели (`CaptchaModel`)

Модель представляет собой комбинацию сверточных и рекуррентных слоев (CRNN), специально разработанную для распознавания последовательностей на изображениях:

1.  **Сверточный блок (CNN)**:
    *   Состоит из 6 сверточных слоев (`Conv2d`) с функциями активации `ReLU` и нормализацией по батчу (`BatchNorm2d`).
    *   Применяются слои пулинга (`MaxPool2d`) для уменьшения пространственной размерности карт признаков.
    *   Этот блок служит для извлечения иерархических признаков из входного изображения CAPTCHA.

2.  **Преобразование для RNN**:
    *   Выходные данные CNN (карты признаков) преобразуются: изменяется порядок измерений (`permute`) и форма (`reshape`), чтобы соответствовать формату входа для RNN (последовательность признаков).

3.  **Рекуррентный блок (RNN)**:
    *   Двунаправленный LSTM (`nn.LSTM`) с двумя слоями. LSTM обрабатывает последовательность признаков, извлеченных CNN, учитывая контекст в обоих направлениях (вперед и назад).
    *   Применяется Dropout для регуляризации и предотвращения переобучения.

4.  **Полносвязный слой (FC)**:
    *   Линейный слой (`nn.Linear`) преобразует выход LSTM (скрытые состояния для каждого временного шага) в распределение вероятностей по всем классам алфавита.
    *   К выходу применяется `LogSoftmax`, так как модель используется с `CTCLoss`.

Общее количество классов для модели равно `len(alphabet) + 1`, где `+1` соответствует "пустому" символу (blank label), требуемому для `CTCLoss`.

## Вклад в проект

Мы приветствуем вклад в развитие проекта! Если вы хотите помочь, пожалуйста, следуйте этим шагам:

1.  Сделайте форк репозитория.
2.  Создайте новую ветку для ваших изменений (`git checkout -b feature/ваша-фича`).
3.  Внесите свои изменения и сделайте коммит (`git commit -am 'Добавлена новая фича'`).
4.  Отправьте изменения в ваш форк (`git push origin feature/ваша-фича`).
5.  Создайте Pull Request.

Пожалуйста, убедитесь, что ваш код соответствует стандартам проекта и включает необходимые тесты (если применимо).

## Лицензия

Этот проект лицензирован под лицензией, указанной в файле `LICENSE`. Если файл `LICENSE` отсутствует, рекомендуется уточнить условия лицензирования у авторов проекта.
(Примечание: В репозитории есть файл `LICENSE`. Убедитесь, что его содержимое соответствует ожиданиям).
